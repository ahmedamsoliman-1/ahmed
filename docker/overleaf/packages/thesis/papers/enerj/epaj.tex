\input{ott_epaj_include.tex}

\section{Introduction}

Studies repeatedly show that approximate applications consist of both
\emph{critical} and \emph{non-critical} components~\cite{li07, ersa, li06,
  dekruijf-selse09, flikker, qosprof, relax, wong-selse06,
  perforation, rinard-onward}.
For example, an image renderer can tolerate errors in the pixel
data it outputs---a small number of erroneous pixels may be acceptable
or even undetectable. However, an error in a jump table could lead to
a crash, and even small errors in the image file format might make the
output unreadable.

Distinguishing
between the critical and non-critical portions of a program is
difficult. Prior
proposals have used annotations on code blocks (e.g., \cite{relax}) and
data allocation sites (e.g., \cite{flikker}). These annotations,
however, do not offer any guarantee that the fundamental operation of the
program is not compromised. In other words, these annotations are either
{\em unsafe} and may lead to unacceptable program behavior or {\em
  need dynamic checks} that end up consuming energy. We need a
way to allow programmers to compose programs from approximate
and precise components safely. Moreover, we need to guarantee safety statically
to avoid spending energy
checking properties at runtime. The key insight in this work is
the application of type-based information-flow tracking~\cite{infflow-survey}
ideas to address these problems.

This chapter proposes a model for approximate programming that is
both \emph{safe} and \emph{general}. We use a type system that
isolates the precise portion of the program from the
approximate portion. The programmer must explicitly delineate flow
from approximate data to precise data. The model is thus \emph{safe}
in that it guarantees precise computation unless given explicit
programmer permission.  Safety is
statically enforced and no dynamic checks are
required, minimizing the overheads imposed by
the language.

We present EnerJ, a language for principled approximate
computing.
EnerJ extends Java
with type qualifiers that distinguish between
\emph{approximate} and \emph{precise} data types.
Data annotated with the ``approximate'' qualifier can be stored
approximately and computations involving it can be performed
approximately. EnerJ also provides \emph{endorsements}, which are
programmer-specified points at which approximate-to-precise data flow
may occur. The language supports programming constructs for
algorithmic approximation, in which the programmer produces different
implementations of functionality for approximate and precise data.
We formalize a core of EnerJ and prove a
non-interference property in the absence of endorsements.

Our programming model is \emph{general} in that it unifies approximate
data storage, approximate computation, and approximate algorithms.
Programmers use a single abstraction to apply all three
forms of approximation.
The model is also \emph{high-level and
portable:} the implementation (compiler, runtime system, hardware)
is entirely responsible for choosing the energy-saving mechanisms to
employ and when to do so, guaranteeing correctness for precise data
and ``best effort'' for the rest.

While EnerJ is designed to support general approximation strategies
and therefore ensure full portability and backward-compatibility, we
demonstrate its effectiveness using a proposed approximation-aware
architecture with approximate memory and imprecise
functional units. We have ported several applications to EnerJ to
demonstrate that a small amount of annotation can allow a program to
save a large amount of energy while not compromising quality of
service significantly.


\section{A Type System for Approximate Computation}
\label{enerj:sec:typesys}

This section describes EnerJ's extensions to Java, which
are based on a system of type qualifiers. We first describe the
qualifiers themselves. We next explain how programmers precisely
control when approximate data can affect
precise state. We describe the implementation of approximate
operations using overloading. We then discuss
conditional statements and the prevention of implicit flows.
Finally, we describe the type system's extension to
object-oriented programming constructs and its interaction with
Java arrays.

% The idea is to have the programmer annotate data that can be handled
% approximatelly via type annotations.  The compiler then uses this
% information to allocate approximate data in approximate storage and to
% generate instructions that operate approximately only when they do not
% impact precise data. As our evaluation demonstrates, this
% \emph{data-centric} annotation provides a succinct way to safely
% approximate par} of the program while keeping the rest precise.

EnerJ implements these language constructs as backwards-compatible
additions to Java extended with type
annotations \cite{jsr308}.
Table~\ref{enerj:table:language} summarizes our extensions and their
concrete syntax. %the
%language constructs used along with their concrete syntax.

\begin{table}
\begin{centering}
\begin{tabular}{c p{2.1in} c}
Construct & Purpose & Section \\
\hline

\ilcode{@Approx}, \ilcode{@Precise}, \ilcode{@Top} &
Type annotations: qualify any type in the program. (Default is
\ilcode{@Precise}.)&
\ref{enerj:types} \\

\ilcode{endorse($e$)} &
Cast an approximate value to its precise equivalent. &
\ref{enerj:endorsement} \\

\ilcode{@Approximable} &
Class annotation: allow a class to have both precise and approximate
instances. &
\ref{enerj:objects} \\

\ilcode{@Context} &
Type annotation: in approximable class definitions, the precision of
the type depends on the precision of the enclosing object. &
\ref{enerj:context} \\

\ilcode{\_APPROX} &
Method naming convention:
this implementation of the method may be invoked when the receiver
has approximate type. &
\ref{enerj:overload}

\end{tabular}
\end{centering}
\caption{Summary of EnerJ's language extensions.}
\label{enerj:table:language}
\end{table}

\subsection{Type Annotations}
\label{enerj:types}

Every value in the program has an approximate or precise
type. The programmer annotates types with the
\ilcode{@Approx} and \ilcode{@Precise} qualifiers. Precise types
are the default, so typically only \ilcode{@Approx} is
made explicit.
It is illegal to assign an
approximate-typed value into a precise-typed variable.
Intuitively, this prevents direct flow of data from approximate to
precise variables.
For instance, the following assignment is illegal:
\begin{lstlisting}
@Approx int a = ...;
int p; // precise by default
p = a; // illegal
\end{lstlisting}
Approximate-to-precise data flow is clearly undesirable, but it seems
natural to allow flow in the opposite direction. For primitive
Java types, we allow precise-to-approximate data flow via subtyping.
Specifically, we make each precise primitive Java type a subtype of
its approximate counterpart. This choice permits, for instance,
the assignment \ilcode{a = p;} in the above example.

For Java's reference (class) types, this
subtyping relationship is unsound. The qualifier of a reference can
influence the qualifiers of its fields (see Section~\ref{enerj:objects}),
so subtyping on mutable references is unsound for standard reasons.
We find that this limitation is not cumbersome in practice.

We also introduce a \ilcode{@Top} qualifier to denote the common
supertype of \ilcode{@Approx} and \ilcode{@Precise} types.

\paragraph{Semantics of approximation}
EnerJ takes an all-or-nothing approach to approximation.
Precise values carry traditional guarantees of correctness; approximate
values have no guarantees.
The language achieves generality by leaving approximation patterns
unspecified, but programmers can informally expect approximate data to
be ``mostly correct'' and adhere to normal execution semantics except
for occasional errors.

An approximate program's result quality is an orthogonal concern (see
\secref{princ:safety}).
Separate systems should complement EnerJ by tuning the frequency and intensity
of errors in approximate data.
The next two chapters in this part of the dissertation, on probability types
and probabilistic assertions, propose systems that address the output-quality
question.

\subsection{Endorsement}
\label{enerj:endorsement}
Fully isolating approximate and precise parts of a program would
likely not be very useful. Eventually a program needs to store data,
transmit it, or present it to the programmer---at which point the program
should begin behaving precisely. As a general pattern, programs we
examined frequently had a phase of fault-tolerant computation followed
by a phase of fault-sensitive reduction or output.
For instance, one application consists of a resilient image
manipulation phase followed by a critical checksum over
the result (see Section~\ref{enerj:effort}).
It is essential that data be
occasionally allowed to break the strict separation enforced by the type
system. % as described.

We require the programmer to
control explicitly when approximate data can affect precise state. To
this end, we borrow the concept (and term) of {\em
  endorsement} from past work on information-flow control~\cite{endorsement}.
An explicit static function \ilcode{endorse} allows the
programmer to use approximate data as if it were
precise. The function acts as a cast from any approximate type to its
precise equivalent. Endorsements may have implicit runtime effects;
they might, for example, copy values from approximate to precise memory.

The previous example can be made legal with an endorsement:
\begin{lstlisting}
@Approx int a = ...;
int p; // precise by default
p = endorse(a); // legal
\end{lstlisting}
By inserting an endorsement,
the programmer certifies that the approximate data is handled
intelligently and will not cause undesired results in the precise part of
the program.


\subsection{Approximate Operations}
\label{enerj:sec:approx}

The type system thus far provides a mechanism for approximating
\emph{storage}. Clearly, variables with approximate type may be
located in unreliable memory modules. However,
approximate \emph{computation} requires additional features. %is not immediately apparent from the
%types.

We introduce approximate computation by overloading operators and
methods based on the type qualifiers. For instance, our
language provides two signatures for the \ilcode{+} operator on
integers: one taking two precise integers and producing a precise
integer and the other taking two approximate integers and producing an
approximate integer. The latter may compute its result
approximately and thus may run on low-power hardware.
Programmers can extend this concept by overloading methods with
qualified parameter types.

\paragraph{Bidirectional typing}
The above approach occasionally applies precise operations where
approximate operations would suffice. Consider the expression \ilcode{a = b + c}
where \ilcode{a} is approximate but \ilcode{b} and \ilcode{c} are
precise. Overloading selects precise addition even
though the result will only be used approximately. It is possible to force
an approximate operation by upcasting either operand to an approximate
type, but we provide a slight optimization that avoids the need for additional
annotation.
EnerJ implements an extremely simple form of bidirectional type checking
\cite{bdtyping} that applies approximate arithmetic operators
when the result type is approximate: on the right-hand side of assignment
operators and in method arguments. We find that this small optimization makes
it simpler to write approximate arithmetic expressions that include precise
data.


\subsection{Control Flow}
To provide the desired property that information never flows from
approximate to precise data, we must disallow \emph{implicit flows} that occur
via control flow. For example, the following program
violates the desired isolation property:
\begin{lstlisting}
@Approx int val = ...;
boolean flag; // precise
if (val == 5) { flag = true; } else { flag = false; }
\end{lstlisting}
Even though \ilcode{flag} is precise and no endorsement is
present, its value is affected by the approximate variable \ilcode{val}.

EnerJ avoids this situation by prohibiting approximate values in
conditions that affect control flow (such as \ilcode{if} and
\ilcode{while} statements).
In the
above example, \ilcode{val == 5} has approximate type
because the approximate version of \ilcode{==} must be used. Our
language disallows this expression in the condition, though the
programmer can work around this restriction using
\ilcode{if(endorse(val == 5))}.

This restriction is conservative: it prohibits approximate conditions even
when the result can affect only approximate data. A more sophisticated
approach would allow only approximate values to be produced in statements
conditioned on approximate data. We find that our simpler approach
is sufficient; endorsements allow the programmer to work around the
restriction when needed.

\subsection{Objects}
\label{enerj:objects}
EnerJ's type qualifiers are not limited to primitive types.
Classes also support approximation.
Clients of an \emph{approximable} class can create
precise and approximate instances of the class. The author of the
class defines the meaning of approximation for the class.
Approximable classes are distinguished by the \ilcode{@Approximable}
class annotation. Such a class exhibits qualifier polymorphism
\cite{qualifiers}: types within the class definition
may depend on the qualifier of the instance.

Precise class types are not subtypes of their approximate
counterparts, as is the case with primitive types (Section~\ref{enerj:types}).
Since Java uses references for all object types, this subtyping relationship
would allow programs to create an approximate alias to a precise object;
the object could then be mutated through that reference as if it were
approximate.
To avoid this source of unsoundness, we make object types invariant with
respect to EnerJ's type qualifiers.

\subsubsection{Contextual Data Types}
\label{enerj:context}
The \ilcode{@Context} qualifier is available
in definitions of non-static members of approximable classes.
The meaning of
the qualifier depends on the precision of the instance of the
enclosing class. (In terms of qualifier polymorphism, \ilcode{@Context}
refers to the class' qualifier parameter, which is determined by the
qualifier placed on the instance.)
Consider the following class definition:
\begin{lstlisting}
@Approximable class IntPair {
  @Context int x;
  @Context int y;
  @Approx int numAdditions = 0;
  void addToBoth(@Context int amount) {
    x += amount;
    y += amount;
    numAdditions++;
  }
}
\end{lstlisting}
If \ilcode{a} is an approximate instance of \ilcode{IntPair}, then the three
fields on the object,
\ilcode{a.x}, \ilcode{a.y}, and \ilcode{a.numAdditions}, are all of approximate
integer type. However, if \ilcode{p} is a precise instance of the class, then
\ilcode{p.x} and \ilcode{p.y} are precise but \ilcode{p.numAdditions} is still
approximate. Furthermore, the argument to the invocation \ilcode{p.addToBoth()}
must be precise; the argument to \ilcode{a.addToBoth()} may be
approximate.

\subsubsection{Algorithmic Approximation}
\label{enerj:overload}
Approximable classes may also specialize method definitions based on their
qualifier.
That is, the programmer can write two implementations:
one to be called when the receiver has
precise type and another that can be called when the receiver is approximate.
Consider the following implementations of a mean calculation over a list of
floats:
\begin{lstlisting}
@Approximable class FloatSet {
  @Context float[] nums = ...;
  float mean() {
    float total = 0.0f;
    for (int i = 0; i < nums.length; ++i)
      total += nums[i];
    return total / nums.length;
  }
  @Approx float mean_APPROX() {
    @Approx float total = 0.0f;
    for (int i = 0; i < nums.length; i += 2)
      total += nums[i];
    return 2 * total / nums.length;
  }
}
\end{lstlisting}
EnerJ uses a naming convention, consisting of the \ilcode{\_APPROX}
suffix, to distinguish methods overloaded on precision. The first
implementation of \ilcode{mean} is called when the receiver is
precise.
The second implementation calculates an approximation of the mean: it
averages only half the numbers in the set. This implementation will be
used for the invocation \ilcode{s.mean()} where \ilcode{s} is an
approximate instance of \ilcode{FloatSet}.
Note that the compiler automatically decides which implementation of the
method to invoke depending on the receiver type; the same invocation is used in
either case.

It is the programmer's responsibility to ensure that the two
implementations are similar enough that they can be safely substituted.
This is important for backwards compatibility
(a plain Java compiler will ignore the naming convention and always
use the precise version) and ``best effort'' (the implementation may
use the precise version if energy is not constrained).

This facility makes it simple to couple algorithmic approximation with
data approximation---a single annotation makes an instance use both
approximate data (via \ilcode{@Context}) and approximate code (via
overloading).

\subsection{Arrays}
The programmer can declare arrays with approximate element types, but
the array's length is always kept precise for memory safety.
We find that programs often
use large arrays of approximate primitive elements; in this case, the
elements themselves are all approximated and only the length requires
precise guarantees.

EnerJ prohibits approximate integers from being used as array
subscripts. That is, in the expression \ilcode{a[i]}, the value \ilcode{i} must
be precise. This makes it easier for the programmer to
prevent out-of-bounds errors due to approximation.

\section{Formal Semantics}
\label{enerj:semantics}
To study the formal semantics of EnerJ, we define the minimal language
FEnerJ. The language is based on Featherweight Java~\cite{fjava}
and adds precision qualifiers and state. The formal language omits
EnerJ's endorsements and thus can guarantee isolation of approximate and
precise program components. This isolation property suggests that,
\emph{in the absence of endorsement}, approximate data in an EnerJ program
cannot affect precise state.

Appendix~\ref{app:enerj} formalizes this language and
proves type soundness as well as a non-interference
property that demonstrates the desired isolation of approximate and
precise data.


\subsection{Programming Language}


\newcommand{\lit}{\mathcal{L}}
\newcommand{\lost}{\texttt{lost}}
\newcommand{\context}{\texttt{context}}
\renewcommand{\approx}{\texttt{approx}}
% the other approx is the math operator. Don't use it.
\newcommand{\precise}{\texttt{precise}}
\renewcommand{\top}{\texttt{top}}
% the other top is the math operator. Don't use it.
\newcommand{\comb}{\ensuremath{\triangleright}}

\newcommand{\sG}{\ensuremath{\mathit{^{s}\!\Gamma}}}
\newcommand{\rG}{\ensuremath{\mathit{^{r}\!\Gamma}}}



\newcommand\predefskip[0]{\vspace{2mm plus1mm}\hspace*{3mm}}
\renewenvironment{ottdefnblock}[3][]{\predefskip \small\framebox{\mbox{#2}}\quad #3\\[0pt]}{}

% instead of a \quad just use a ``\ `` space
\renewcommand{\ottdrule}[4][]{{\displaystyle\frac{\begin{array}{l}#2\end{array}}{#3}\ \ottdrulename{#4}}}

\renewcommand{\ottusedrule}[1]{\hspace*{7mm}$#1$}


\begin{figure}
\small
\[
\begin{array}{l}
\begin{array}{r@{\quad ::= \quad }l}
\mathit{Prg}      &  \overline{\mathit{Cls}},\ C,\ e \\

\mathit{Cls}      &  \mathtt{class}\ \mathit{Cid}\ \mathtt{extends}\ C\
\{\ \mathit{\overline{fd}\ \overline{md}}\ \} \\

C        &  \mathit{Cid}\ |\ \mathtt{Object} \\

P        &  \mathtt{int}\ |\ \mathtt{float} \\

q        &  \mathtt{precise}\ |\ \mathtt{approx}\ |\ \mathtt{top}
            \ |\ \mathtt{context}\ |\ \mathtt{lost}\\

T        &  q\ C \ |\ q\ P\\

\mathit{fd}   &  T\ f\mathtt{;} \\

\mathit{md}   &  T\ m(\overline{\mathit{T\ pid}})\ \mathit{q}\ \{\ e\ \} \\

x        &  \mathit{pid}\ |\ \mathtt{this} \\

e        &  \mathtt{null}\ |\ \lit\ |\ x\ |\ \mathtt{new}\ q\ C()\ |\
                e.f\ |\ e_0.f \mathtt{:=} e_1\ | \
                e_0.m(\overline{e})\\
\multicolumn{2}{l}{\hspace{1.8cm} |\
                (q\ C)\ e \ | \
                e_0 \oplus e_1 \ | \
         \mathtt{if(} e_0 \mathtt{)\ \{} e_1 \mathtt{\}\ else\ \{} e_2 \mathtt{\}}}\\

\end{array}
\\
\vspace{-2mm}
\\

\
\begin{array}{r@{\qquad}l@{\qquad\qquad}r@{\qquad}l}
f        &  \mbox{field identifier} &
\mathit{pid}      &  \mbox{parameter identifier}\\
m        &  \mbox{method identifier} &
\mathit{Cid}      &  \mbox{class identifier}\\
\end{array}
\end{array}
\]

\caption{The syntax of the FEnerJ programming language.
The symbol $\overline{A}$ denotes a sequence of elements $A$.
\label{enerj:fig:syntax}
}
\end{figure}

Figure~\ref{enerj:fig:syntax} presents the syntax of FEnerJ.
Programs consist of a sequence of classes, a main class, and a main
expression. Execution is modeled by instantiating
the main class and then evaluating the main expression.

A class definition consists of a name, the name of the superclass, and
field and method definitions.
The \ilcode{@Approximable} annotation is not modeled in FEnerJ; all classes in
the formal language can have approximate and precise instances and
\ilcode{this} has \ilcode{@Context} type.
The annotation is required only in order
to provide backward-compatibility with Java so that \ilcode{this} in a
non-approximable class has \ilcode{@Precise} type.

We use \textit{C} to range over class names and \textit{P} for the
names of primitive types.
We define the precision qualifiers \textit{q} as discussed in Section~\ref{enerj:types},
but with the additional qualifier \lost{}; this qualifier is used to
express situations when context information is not expressible
(i.e., lost).
Types $T$ include qualifiers.

Field declarations consist of the field type and name.
Method declarations consist of the return type, method name, a
sequence of parameter types and identifiers, the method precision, and
the method body. We use the method precision qualifier to denote
overloading of the method based on the precision of the receiver as
introduced in Section~\ref{enerj:overload}.
Variables are either a parameter identifier or the special variable
\texttt{this}, signifying the current object.

The language has the following expressions:
the null literal,
literals of the primitive types,
reads of local variables,
instantiation,
field reads and writes,
method calls,
casts,
binary primitive operations, and
conditionals.
We present the representative rules for
field reads, field writes, and conditionals.


\paragraph{Subtyping}
Subtyping is defined using an ordering of the precision qualifiers and
subclassing.

% A little bit of magic to remove rule names (for space).
\renewcommand{\ottdrulename}[1]{}

The following rules define the ordering of precision qualifiers:

\vspace{1.0ex}
\noindent
\begin{ottdefnblock}[#1]{$ \ottnt{q} \  \textsf{$<:_{\mathrm{q}}$} \  \ottnt{q'} $}{\ottcom{ordering of precision qualifiers}}
\begin{centering}
\ottusedrule{\ottdruleqqXXlost{}} \hspace{1em}
\ottusedrule{\ottdruleqqXXtop{}} \hspace{1em}
\ottusedrule{\ottdruleqqXXrefl{}}\\
\end{centering}
\end{ottdefnblock}
\vspace{1.5ex}

\noindent
Recall that \top{} qualifies the common supertype of \precise{} and
\approx{} types.
Every qualifier other than \top{} is below \lost{};
every qualifier is below \top{}; and the relation is
reflexive.
Note that the \precise{} and \approx{} qualifiers are not
related.

Subclassing is the reflexive and transitive closure of the relation
induced by the class declarations.
Subtyping takes both ordering of precision qualifiers and subclassing
into account.
For primitive types, we additionally have that a precise type is a
subtype of the approximate type as described in Section~\ref{enerj:types}.


\paragraph{Context adaptation}

We use \emph{context adaptation} to replace the \context{} qualifier
when it appears in a field
access or method invocation. Here the left-hand side
of \comb{} denotes the qualifier of the receiver expression;
the right-hand side is the precision qualifier of the field or in the method
signature.

\vspace{0.5ex}
\noindent
\begin{ottdefnblock}[#1]{$ \ottnt{q} \, \rhd\,  \ottnt{q'} \ \  \textsf{=} \ \  \ottnt{q''} $}{\ottcom{combining two precision qualifiers}}
\ottusedrule{\hfill \ottdruleqcqXXcontext{} \hfill}\\[2mm]
\ottusedrule{\ottdruleqcqXXlost{} \hfill
\ottdruleqcqXXfixed{}\ \ }\\
\end{ottdefnblock}

\noindent
Note that \context{} adapts to \lost{} when the left-hand-side qualifier
is \top{} because the appropriate qualifier cannot be determined.

We additionally define $\comb$ to take a type as the
right-hand side; this adapts the precision qualifier of the type.


We define partial look-up functions FType and MSig that determine the field
type and method signature for a given field/method in an access or
invocation.
Note that these use the adaptation rules described above.


\paragraph{Type rules}

The static type environment \sG{} maps local variables to their
declared types.

Given a static environment, expressions are typed as follows:

\vspace{1.0ex}
\noindent
\begin{ottdefnblock}[#1]{$ \mathit{ {^s}\!\Gamma} \  \textsf{$\vdash$} \  \ottnt{e} \  \textsf{:} \  T $}{\ottcom{expression typing}}
\begin{centering}
\ottusedrule{\ottdruletrXXread{}}\\[2mm]
\ottusedrule{\ottdruletrXXwrite{}}\\[2mm]
\ottusedrule{\ottdruletrXXcond{}}\\
\end{centering}
\end{ottdefnblock}
\vspace{1.5ex}

A field read determines the type of the receiver expression and then
uses FType to determine the adapted type of the field.

A field write similarly determines the adapted type of the field and
checks that the right-hand side has an appropriate type.
In addition, we ensure that the adaptation of the declared field type
did not lose precision information.
Notice that we can read a field with lost precision information, but
that it would be unsound to allow the update of such a field.

Finally, for the conditional expression, we ensure that the condition
is of a precise primitive type and that there is a common type $T$
that can be assigned to both subexpressions.



\subsection{Operational Semantics}

The runtime system of FEnerJ models the heap $h$ as a mapping from
addresses $\iota$ to objects, where objects are a pair of the runtime
type $T$ and the field values $v$ of the object.
% Primitive values store both their precision and actual value.
% The runtime environment \rG{} is a tuple: the first component is the
% precision of the environment and the second component maps local
% variables to their values.
The runtime environment \rG{} maps local variables $x$ to values
$v$.

The runtime system of FEnerJ defines a standard big-step operational
semantics:

\vspace{1.0ex}
\noindent
\begin{ottdefnblock}[#1]{$ \mathit{ {^r}\!\Gamma} \  \textsf{$\vdash$} \  \ottnt{h} ,  \ottnt{e} \ \leadsto\  \ottnt{h'} ,  v $}{\ottcom{big-step operational semantics}}
\begin{centering}
\ottusedrule{\ottdruleosXXread{}}\\[1mm plus 1mm minus .5mm]
\ottusedrule{\ottdruleosXXwrite{}}\\[1mm plus 1mm minus .5mm]
\ottusedrule{\ottdruleosXXcondXXt{}}\\[1mm plus 1mm minus .5mm]
\ottusedrule{\ottdruleosXXcondXXf{}}\\
\end{centering}
\end{ottdefnblock}
\vspace{1.5ex}

\noindent
These rules reflect precise execution with conventional precision
guarantees.
To model computation on an execution substrate that supports approximation,
the following rule could be introduced:
%
\[
\ottdruleosXXapprox{}
\]
%
We use $\cong$ to denote an equality that disregards approximate
values for comparing heaps and values with identical types.
The rule permits any
approximate value in the heap to be replaced with any other value
of the same type
and any expression producing a value of an approximate type to
produce any other value of that type instead.
This rule reflects EnerJ's
lack of guarantees for approximate values.



\subsection{Properties}

We prove two properties about FEnerJ: type soundness and
non-interference.
Appendix~\ref{app:enerj} proves these theorems.

The usual type soundness property expresses that, for a well-typed
program and corresponding static and runtime environments, we know
that
(1) the runtime environment after evaluating the expression is still
well formed, and
(2) a static type that can be assigned to the expression can also be
assigned to the value that is the result of evaluating the expression.
Formally:
\[
\small
\left.
\begin{array}{l}
|- \mathit{Prg}\ \ \mathtt{OK}\ \ \wedge\  |- h, \rG : \sG\\
\sG |- e : T\\
\rG |- h, e \leadsto h', v\\
\end{array}
\right\} ==> \left\{
\begin{array}{l}
|- h', \rG : \sG\\
h', \rG(\mathtt{this}) |- v : T\\
\end{array}
\right.
\]
The proof is by rule induction over the operational semantics; in
separate lemmas we formalize that the context adaptation operation
\comb{} is sound.


% \medskip
% I think it's OK if these paragraphs are adjacent. -- ALDS

The non-interference property of FEnerJ guarantees that
approximate computations do not influence precise values. Specifically,
changing approximate values in the heap or runtime environment
does not change the precise parts of the heap or the result of the
computation.
More formally, we show:
\[
\small
\left.
\begin{array}{l}
|- \mathit{Prg}\ \ \mathtt{OK} \ \ \wedge\  |- h, \rG : \sG\\
\sG |- e : T\\
\rG |- h, e \leadsto h', v\\
h \cong \tilde{h}  \ \wedge\  \rG \cong \tilde{\rG}\\
|- \tilde{h}, \tilde{\rG} : \sG\\
\end{array}
\right\}
==>
\left\{
\begin{array}{l}
\tilde{\rG} |- \tilde{h}, e -> \tilde{h'}, \tilde{v}\\
h' \cong \tilde{h'}\\
v \cong \tilde{v}
\end{array}
\right.
\]
For the proof of this property we introduced a \emph{checked}
operational semantics that ensures in every evaluation step that the
precise and approximate parts are separated.
We can then show that the evaluation of a well-typed
expression always passes the checked semantics of the programming
language.




\section{Execution Model}
\label{enerj:sec:execution}

While an EnerJ program distinguishes abstractly between approximate and
precise data, it does not define the particular approximation strategies
that are applied to the program. (In fact, one valid execution is to ignore all
annotations and execute the code as plain Java.) An approximation-aware
execution substrate is needed to take advantage of EnerJ's annotations.
We examine approximation mechanisms at the architecture level that work at
granularity of individual instructions and individual memory
locations~\cite{truffle, quora}.
This section describes our hardware model, the ISA extensions
used for approximation, and how the extensions enable energy savings.
The Truffle paper~\cite{truffle} explores the ISA
design and microarchitectural mechanisms for approximation in more detail.

As a complement to the approximate hardware considered here, a compiler or runtime system on top of commodity hardware can also
offer approximate execution features: lower floating point
precision, elision of memory operations, etc.
(Algorithmic approximation, from
Section~\ref{enerj:objects}, is independent of the
execution substrate.)
The ACCEPT compiler infrastructure in \chref{accept} exploits this
category of approximations using an annotation language similar to EnerJ.

\subsection{Approximation-Aware ISA Extensions}
\label{enerj:sec:isa}

We want to leverage both approximate {\em storage} and
approximate {\em operations}.  Our hardware model offers approximate
storage in the form of unreliable registers, data caches, and main
memory. Approximate and precise registers are distinguished based on
the register number. Approximate data stored in memory is
distinguished from precise data based on address; regions of physical
memory are marked as approximate and, when accessed, are stored in
approximate portions of the data cache. For approximate operations,
we assume specific instructions for approximate
integer ALU operations as well as approximate floating point
operations. Approximate instructions can use special functional units that
perform approximate operations. Figure~\ref{enerj:fig:hwmodel} summarizes
our assumed hardware model.

\begin{figure}[t]
  \centering
    \includegraphics[width=0.85\columnwidth]{figs/hwmodel.pdf}
      \caption{Hardware model assumed in our system. Shaded areas indicate
        components that support approximation.
        Registers and the data cache have SRAM storage cells that
        can be made approximate by decreasing supply voltage.
        Functional units support approximation via supply voltage
        reduction. Floating point functional units also support approximation
        via smaller
        mantissas. Main memory (DRAM) supports approximation by reducing
        refresh rate.\label{enerj:fig:hwmodel}}
\end{figure}

An instruction stream may have a mix of approximate and precise
instructions. Precise instructions have the same guarantees as
instructions in today's ISAs. Note that an approximate instruction is
simply a ``hint'' to the architecture that it may apply a variety of
energy-saving approximations when executing the given instruction. The
particular approximations employed by a given architecture are not
exposed to the program; a processor supporting no approximations just
executes approximate instructions precisely and saves no
energy. An approximation-aware ISA thus allows a single
binary to benefit from new approximations as they are
implemented in future microarchitectures.

\paragraph{Layout of approximate data} Our hardware model supports
approximate memory data at a cache line granularity, in which software
can configure any line as approximate. This can be supported by having a
bit per line in each page that indicates whether the corresponding line is
approximate. Based on that bit, a cache controller determines
the supply voltage of a line (lower for approximate lines), and the
refresh rate for regions of DRAM\@. This bitmap needs to be kept
precise. With a typical cache line size of 64 bytes, this is less
than 0.2\% overhead. Note that both selective supply voltage for
caches~\cite{drowsycaches} and selective refresh rate for
DRAM~\cite{smartrefresh} are hardware techniques that have been
proposed in the past.

Setting approximation on a cache line basis requires the runtime
system to segregate approximate and precise data in different
cache lines. We propose the following simple
technique for laying out objects with both approximate and precise
fields. First, lay out the precise portion of the object (including
the \texttt{vtable} pointer) contiguously. Each cache line containing at least
one precise field is marked as precise. Then, lay out the approximate
fields after the end of the precise data. Some of this data may
be placed in a precise line (that is, a line containing some precise
data already); in this case, the approximate data stays precise and
saves no memory energy.
(Note that wasting space in the precise line in order to place the
data in an approximate line would use more memory and thus more
energy.)
The remaining approximate fields that do not
fit in the last precise line can be placed in approximate lines.

Fields in superclasses may not be reordered in subclasses.
Thus, a subclass of a class with approximate data may waste space in
an approximate line in order to place precise fields of the subclass
in a precise line.

While we simulate the artifacts of this layout scheme for our evaluation,
a finer granularity of approximate memory storage would mitigate or
eliminate the resulting loss of approximation.
More sophisticated layout algorithms could also improve energy savings;
this is a target for compile-time optimization.
Note that
even if an approximate field ends up stored in precise memory, it will
still be loaded into approximate registers and be subject to
approximate operations and algorithms.

The layout problem is much simpler for arrays of approximate primitive
types. The first line, which
contains the length and type information, must be precise, with all remaining
lines approximate.


\subsection{Hardware Techniques for Saving Energy }
\label{enerj:strategies}

% http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/power_provisioning.pdf
%% Server
% processor: 80W, memory: 36W == ~ 54% total

%% smartphone
% http://ertos.nicta.com.au/publications/papers/Carroll_Heiser_10.pdf
% 16 cpu + 4 RAM == ~20% total. radio dominates.

%%laptop http://www.google.com/url?sa=t&source=web&cd=1&sqi=2&ved=0CBMQFjAA&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.87.5604%26rep%3Drep1%26type%3Dpdf&ei=c5vPTMbRJIOisAPQloWqAw&usg=AFQjCNG8xSBDhqYtF9jopXkA80vVLnnEZQ


% http://www.eecs.umich.edu/~taustin/papers/TVLSI09-subliminal.pdf
% http://www.eecs.umich.edu/~taustin/papers/MICRO36-Razor.pdf
% http://passat.crhc.illinois.edu/rakeshk/hpca10_cam.pdf
There are many strategies for saving energy with approximate
storage and data operations. This section discusses some of the
techniques explored in prior research. We assume these techniques in
our simulations, which we describe later. The techniques are summarized
in Table~\ref{enerj:table:approximations}.


\paragraph{Voltage scaling} Aggressive voltage
scaling can result in over $30\%$ energy reduction with
$\sim \! 1\%$ error rate~\cite{razor} and $22\%$ reduction with
$\sim \! 0.01\%$ error rate.  Recent work~\cite{relax} proposed to
expose the errors to applications that can tolerate it and saw similar
results. In our model, we assume aggressive voltage scaling for the
processor units executing approximate instructions,
including integer and floating-point operations. As for an
error model, the choices are single bit flip, last value, and random
value. We consider all three but our evaluation mainly depicts the
random-value assumption, which is the most realistic.

\paragraph{Floating point operation width}
A direct approach to approximate arithmetic operations on floating point values
is to ignore part of the mantissa in the operands. As observed in
\cite{bitwidthred}, many applications do not need the full mantissa.
According to their model,
a floating-point multiplier using 8-bit mantissas uses 78\% less
energy per operation than a full 24-bit multiplier.

% http://lca.ece.utexas.edu/pubs/isen_micro09.pdf
% leverages freed regions to lower refresh rate.

% http://www.cs.utah.edu/~rajeev/pubs/isca10.pdf

% ftp://ftp.computer.org/press/outgoing/proceedings/Patrick/ADI/sc10%20usb%20drive/data/0000a193.pdf

\paragraph{DRAM refresh rate}
Reducing the refresh rate of dynamic RAM leads to potential data decay
but can substantially reduce power consumption with a low error rate.
As proposed by Liu et al.~\cite{flikker}, an approximation-aware DRAM system
might reduce the refresh rate on lines containing approximate data. As in
that work, we assume that reducing the refresh rate to 1~Hz
reduces power by about 20\%.
In a study performed by Bhalodia~\cite{dramthesis}, a DRAM cell not
refreshed for 10 seconds experiences a failure with per-bit
probability approximately $10^{-5}$. We conservatively assume this error
rate for the reduced refresh rate of 1~Hz.

\paragraph{SRAM supply voltage}
Registers and data caches in modern CPUs consist of static RAM (SRAM)
cells. Reducing the supply voltage to SRAM cells lowers the leakage
current of the cells but decreases the data integrity~\cite{drowsycaches}. As
examined by Kumar~\cite{sramthesis}, these
errors are dominated by \emph{read upsets} and \emph{write failures},
which occur when a bit is read or written. A read upset occurs when
the stored bit is flipped while it is read; a write failure occurs when the
wrong bit is written.
Reducing SRAM supply voltage by 80\% results in
read upset and write failure probabilities of $10^{-7.4}$ and
$10^{-4.94}$ respectively.
\emph{Soft failures}, bit flips in
stored data due to cosmic rays and other events, are comparatively
rare and depend less on the supply voltage.

\medskip
\noindent
Section~\ref{enerj:energymodel} describes the model we use to combine these
various potential energy savings into an overall CPU/memory system energy
reduction.
To put the potential energy savings in perspective, according to
recent studies~\cite{googlepower, aqeel}, the CPU and memory together account
for well over 50\% of the overall system power in servers as well as
notebooks. In a smartphone, CPU and memory account for about 20\% and
the radio typically close to 50\% of the overall
power~\cite{carroll2010}.


% uarch power breakdown -- server, PPro, old.
% http://www.eecs.harvard.edu/~dbrooks/isca2000.pdf
% cache: 12%, reg file: 23%, int unit: 15%, fp unit: 8%.


% http://cseweb.ucsd.edu/users/tullsen/micro09b.pdf
% http://www.cs.utexas.edu/~skeckler/pubs/islped03.ps


\begin{table}
\small
\begin{centering}
\input{results/approximations.tex}
\end{centering}
\caption{Approximation strategies simulated in our evaluation.
Numbers marked with * are educated guesses by the authors; the others
are taken from the sources described in Section~\ref{enerj:strategies}. Note that
all values for the Medium level are taken from the literature.}
\label{enerj:table:approximations}
\end{table}




\section{Implementation}
\label{enerj:sec:impl}

We implement EnerJ as an extension to the Java
programming language based on the
pluggable type mechanism proposed by Papi et al.~\cite{papi}.
EnerJ is implemented using the
Checker Framework\footnote{\url{http://types.cs.washington.edu/checker-framework/}}
infrastructure,
which builds on the
JSR~308\footnote{\url{http://types.cs.washington.edu/jsr308/}}
extension to Java's annotation facility. JSR~308 permits annotations on
any explicit type in the program.
The EnerJ type checker extends the rules from Section~\ref{enerj:semantics} to all of
Java, including arrays and generics.
% WMD removed the following. We implemented more than just the rules
% in \ref{enerj:semantics}.
% We implement a checker that verifies the typing rules described in
% Section~\ref{enerj:semantics} using JSR~308's associated Checker Framework
% infrastructure.
% Turning off this footnote for now for anonymity, but we should put it
% back for the final version. --ALDS
% \footnote{Checker Framework:
% http://types.cs.washington.edu/checker-framework/}
We also implement a simulation infrastructure that emulates an
approximate computing architecture as described in Section~\ref{enerj:sec:execution}.
\footnote{The EnerJ type checker and simulator
are available online:
\url{http://sampa.cs.washington.edu/research/approximation/enerj.html}
}

\subsection{Type Checker}
\label{enerj:checker}
EnerJ provides the type qualifiers listed
in Table~\ref{enerj:table:language}---\ilcode{@Approx}, \ilcode{@Precise},
\ilcode{@Top}, and \ilcode{@Context}---as JSR~308 type annotations.
The default type qualifier for unannotated types is \ilcode{@Precise}, meaning
that any Java program may be compiled as an EnerJ program with no change in
semantics. The programmer can add approximations to the
program incrementally.

% The \ilcode{@Approximable} annotation on classes is used by
% our type checker to decide the annotation of the \ilcode{this} reference.
% We decided to use the \ilcode{\_APPROX} naming convention to implement
% algorithmic approximation to stay compatible with JSR~308, which does
% not allow overloading methods that differ only in type qualifiers.

% ALDS: I'm not sure if this paragraph is necessary. First, we've already talked
% about why we need @Approximable and its discussion feels a little out of place
% here. Also, the _APPROX naming convention is not just because overloading on
% qualifiers is impossible: it's because we need to overload on the *receiver*
% type, which is not possible in general.

While reference types may be annotated as \ilcode{@Approx}, this only affects
the meaning of \ilcode{@Context} annotations in the class definition and
method binding on the receiver. Our implementation never
approximates pointers.


\subsection{Simulator}
To evaluate our system, we implement a compiler and runtime
system that executes EnerJ code as if it were running on an
approximation-aware architecture
as described in Section~\ref{enerj:sec:execution}. We instrument method calls,
object creation and destruction, arithmetic operators, and memory
accesses to collect statistics and inject faults.
The runtime system is implemented as a Java library and is invoked by the
instrumentation calls.
It records memory-footprint and arithmetic-operation statistics
while simultaneously injecting transient faults to emulate approximate
execution.

To avoid spurious errors due to approximation, our simulated
approximate functional units never raise divide-by-zero exceptions. Approximate
floating-point division by zero returns the NaN value;
approximate integer divide-by-zero returns zero.


\subsection{Approximations}
Our simulator implements the set of approximation techniques enumerated in
Section~\ref{enerj:strategies}. Table~\ref{enerj:table:approximations} summarizes the
approximations used, their associated error probabilities, and their
estimated energy savings.

Floating-point bit-width reduction is performed when executing Java's
arithmetic operators on operands that are approximate \ilcode{float}
and \ilcode{double} values. SRAM read upsets and write failures are
simulated by flipping each bit read or written with a constant
probability. For DRAM refresh reduction, every bit also has an
independent probability of inversion; here, the probability is
proportional to the amount of time since the last access to the bit.

For the purposes of our evaluation, we distinguish SRAM and DRAM data using the
following rough approximation: data on the heap is considered to be stored
in DRAM; stack data is considered SRAM\@. Future evaluations not constrained by
the abstraction of the JVM could explore a more nuanced model.

\subsection{Energy Model}
\label{enerj:energymodel}
To summarize the effectiveness of EnerJ's energy-saving properties, we estimate
the potential overall savings of the processor/memory system when executing
each benchmark approximately. To do so, we consider a simplified model with
three components to the system's energy consumption: instruction execution,
SRAM storage (registers and cache), and DRAM storage.
Our model omits overheads of implementing or switching to approximate hardware.
For example, we do not model any latency in scaling the voltage on the logic
units.
For this reason, our results can be considered optimistic;
the Truffle paper~\cite{truffle} models approximate hardware in more detail.

To estimate the savings for instruction execution, we assign abstract energy
units to arithmetic operations. Integer operations take 37 units and floating point
operations take 40 units; of each of these, 22 units are consumed by the
instruction fetch and decode stage and may not be reduced by approximation
strategies. These estimations are based on three studies of architectural
power consumption~\cite{mcpat,burger2003,wattch}.
We calculate energy savings in instruction execution by scaling the
non-fetch, non-decode component of integer and floating-point instructions.

We assume that SRAM storage and instructions that access it account
for approximately 35\% of the microarchitecture's power consumption;
instruction execution logic consumes the remainder. To compute the
total CPU power savings, then, we scale the savings from SRAM storage
by 0.35 and the instruction power savings, described above, by 0.65.

Finally, we add the savings from DRAM storage to get an energy number for the
entire processor/memory system. For this, we consider a server-like setting,
where DRAM accounts for 45\% of the power and CPU 55\% \cite{googlepower}. Note
that in a mobile setting, memory consumes only 25\% of power so power savings in
the CPU will be more important \cite{carroll2010}.

\section{Results}
\label{enerj:sec:res}

We evaluate EnerJ by annotating a variety of existing Java
programs. Table~\ref{enerj:table:applications} describes the applications we
used; they have been selected to be relevant in both mobile and server
settings. %, as energy is an important constraint in both
          %environments. %% Already said in intro.

\begin{sidewaystable}
\small
\makebox[\textwidth][c]{%
\input{results/applications_table}%
}
\caption{Applications used in our evaluation,
application-specific metrics for quality of service, and
metrics of annotation density. ``Proportion FP''
indicates the percentage of dynamic arithmetic instructions observed that were
floating-point (as opposed to integer) operations.
}
\label{enerj:table:applications}
\end{sidewaystable}

\paragraph{Applications} We evaluate the FPU-heavy kernels of the SciMark2 benchmark suite to
reflect scientific workloads.\footnote{SciMark2:
  \url{http://math.nist.gov/scimark2/}} ZXing is a bar code reader library
targeted for mobile devices based on the Android operating
system.\footnote{ZXing: \url{http://code.google.com/p/zxing/}} Our workload
decodes QR Code two-dimensional bar code images. jMonkeyEngine is a 2D
and 3D game engine for both desktop and mobile
environments.\footnote{jMonkeyEngine: \url{http://www.jmonkeyengine.com/}}
We run a workload that consists of many 3D triangle intersection
problems, an algorithm frequently used for collision detection in
games.

ImageJ is an image-manipulation program; our workload executes a flood fill
operation.\footnote{ImageJ: \url{http://rsbweb.nih.gov/ij/}} This workload was
selected as representative of error-resilient algorithms with primarily
integer---rather than floating point---data.
Because the code already includes extensive
safety precautions such as bounds checking, our annotation for ImageJ is
extremely aggressive: even pixel coordinates are marked as approximate.
Raytracer is a simple 3D renderer; our workload executes
ray plane intersection on a simple scene.

\paragraph{Annotation approach} We annotated each application
manually. While many possible
annotations exist for a given program, we attempted to strike a
balance between reliability and energy savings. As a rule, however, we
attempted to annotate the programs in a way that never causes
them to crash (or throw an unhandled exception); it is important to
show that EnerJ allows programmers to write approximate programs that
never fail catastrophically. In our experiments, each benchmark produces
an output on every run. This is in contrast to approximation techniques
that do not attempt to prevent crashes \cite{flikker, wong-selse06, li07}.
Naturally, we focused our effort on code where most of the
time is spent.
% ALDS: Past tense is appropriate for procedural descriptions.

Three students involved in the project
ported the applications used in our
evaluation. In every case, we were unfamiliar with the codebase
beforehand, so our annotations did not depend on extensive domain
knowledge. The annotations were not labor intensive.


\paragraph{Quality metrics}
For each application, we measure the
degradation in output quality of approximate executions with respect
to the precise executions. To do so, we define application-specific
quality metrics following the principle in \secref{princ:appspecific}.
The third column in
Table~\ref{enerj:table:applications} shows our metric for each application.

Output error ranges from $0$ (indicating output identical to the
precise version) to $1$ (indicating completely meaningless output). For
applications that produce lists of numbers (e.g., SparseMatMult's output
matrix), we compute the error as the mean entry-wise difference between the
pristine output and the degraded output. Each numerical difference is limited
by $1$, so if an entry in the output is \ilcode{NaN},
that entry contributes an error of $1$. For benchmarks where the output is not
numeric (i.e., ZXing, which outputs a string), the error is $0$ when the output
is correct and $1$ otherwise. %when it is incorrect.


\subsection{Energy Savings}

\begin{figure}
\center
\sffamily
\input{results/approximateness_chart}
\caption{Proportion of approximate storage and computation in each benchmark.
For storage (SRAM and DRAM) measurements, the bars
show the fraction of byte-seconds used in storing approximate data.
For functional unit operations, we show the fraction of dynamic operations
that were executed approximately.}
\label{enerj:fig:approximateness}
\end{figure}

\begin{figure}
\center
\sffamily
\input{results/energy_chart}
\caption{Estimated CPU/memory system energy consumed for
each benchmark. The bar labeled ``B'' represents the baseline value:
the energy consumption for the program running without approximation.
The numbered bars correspond to the Mild, Medium, and Aggressive
configurations in Table~\ref{enerj:table:approximations}.}
\label{enerj:fig:energy}
\end{figure}

Figure~\ref{enerj:fig:approximateness} divides the execution of each
benchmark into DRAM storage, SRAM storage, integer operations, and FP
operations and shows what fraction of each was approximated. For
many of the FP-centric applications we simulated, including the
jMonkeyEngine and Raytracer as well as most of the SciMark
applications, nearly all of the floating point operations were
approximate. This reflects the inherent imprecision of FP
representations; many FP-dominated algorithms are inherently resilient
to rounding effects.
The same applications typically exhibit very little or no
approximate integer operations. The frequency of loop induction
variable increments and other precise control-flow code limits our
ability to approximate integer computation. ImageJ is the only
exception with a significant fraction of integer approximation; this is
because it uses integers to represent pixel values, which are amenable
to approximation.

We quantify
DRAM and SRAM approximation using the proportion of the total byte-seconds in
the execution.
The data shows that
both storage types are frequently used in approximate
mode. Many applications have DRAM approximation rates
of 80\% or higher; it is common to store large data
structures (often arrays) that can tolerate approximation. MonteCarlo and
jMonkeyEngine, in contrast, have very little approximate DRAM data;
this is because both applications keep their principal data in local
variables (i.e., on the stack).

The results depicted assume approximation at the granularity of a
64-byte cache line. As Section~\ref{enerj:sec:isa} discusses, this
reduces the number of object fields that can be stored
approximately. The impact of this constraint on our
results is small, in part because much of the approximate data is
in large arrays. Finer-grain approximate memory could yield a
higher proportion of approximate storage.

% u-Arch Model. Power breakdown:  cache: 12%, reg file: 23%, int unit: 15%, fp unit: 8%.
% all abstract units, but can be used for ratios.
% intALU instructions = 22 + 15
% fpALU instructions =  22 + 8
% ld = 22
% st = 22

% server: mem/cpu 45/55
% mobilde: mem/cpu 25/75

% power model based on:
% http://www.eecs.harvard.edu/~dbrooks/isca2000.pdf
% http://cseweb.ucsd.edu/users/tullsen/micro09b.pdf
% http://www.cs.utexas.edu/~skeckler/pubs/islped03.ps
% http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/power_provisioning.pdf
% http://ertos.nicta.com.au/publications/papers/Carroll_Heiser_10.pdf

To give a sense of the energy savings afforded by our proposed
approximation strategies, we translate the rates of approximation depicted
above into an estimated energy consumption. Figure~\ref{enerj:fig:energy}
shows the estimated energy consumption for each benchmark running on
approximate hardware relative to fully precise execution.
The energy calculation is based on the model
described in Section~\ref{enerj:energymodel}. These simulations apply
all of the approximation strategies described in
Section~\ref{enerj:strategies} simultaneously at their three levels of
aggressiveness. As expected, the total energy saved increases both with
the amount of approximation in the application (depicted in
Figure~\ref{enerj:fig:approximateness}) and with
the aggressiveness of approximation used.

Overall, we observe energy savings from 7\% (SOR in the Mild
configuration) to 38\% (Raytracer in the Aggressive
configuration). The three levels of approximation do not vary greatly
in the amount of energy saved---the three configurations yield average
energy savings of 14\%, 19\%, and 21\% respectively. The majority of
the energy savings come from the transition from zero approximation to
mild approximation. As discussed in the next section, the least
aggressive configuration results in very small losses in output
fidelity across all applications studied.
% This suggests that medium is the preferred approximation degree.
% Actually, I think it suggests that Mild is the preferred aproximation
% degree! This is discussed in the next subsection. --ALDS

The fifth column of Table~\ref{enerj:table:applications} shows the proportion of
floating point arithmetic in each application. In general, applications with
principally integer computation (e.g., ZXing and ImageJ) exhibit less
opportunity for approximation than do floating-point applications (e.g.,
Raytracer). Not only do floating-point instructions offer more energy savings
potential in our model, but applications that use them are typically resilient
to their inherent imprecision.

\subsection{Result Quality Trade-off}
\begin{figure}
\center
\sffamily
\input{results/sensitivity_chart}
\caption{Output error for three different levels of approximation varied
together. Each bar represents the mean error over 20 runs.}
\label{enerj:fig:sensitivity}
\end{figure}

Figure~\ref{enerj:fig:sensitivity} presents the sensitivity of each
annotated application to the full suite of approximations
explored. This output quality reduction is the trade-off for the
energy savings shown in Figure~\ref{enerj:fig:energy}.

While most applications show negligible error for the Mild level of
approximation, applications' sensitivity to error varies greatly for the Medium
and Aggressive configurations. Notably, MonteCarlo, SparseMatMult, ImageJ, and
Raytracer exhibit
very little output degradation under any configuration whereas FFT and SOR lose
significant output fidelity even under the Medium configuration.
This variation suggests that an approximate execution substrate for EnerJ
could benefit from tuning to the characteristics of each application,
either offline via profiling or online via continuous quality measurement
as in Green \cite{green}.
However, even the
conservative Mild configuration offers significant energy savings.

Qualitatively, the approximated applications exhibit gradual degradation of
perceptible output quality. For instance, Raytracer always outputs an image
resembling its precise output, but the amount of random pixel ``noise''
increases with the aggressiveness of approximation. Under the Mild
configuration, it is difficult to distinguish the approximated image from the
precise one.

We also measured the relative impact of various approximation
strategies by running our benchmark suite with each optimization enabled in
isolation. The DRAM errors we modeled have a nearly negligible impact on application output;
floating-point bit width reduction similarly results in at most 12\% quality loss
in the Aggressive configuration. SRAM write errors are much more detrimental to
output quality than read upsets. Functional unit voltage reduction had the
greatest impact on correctness. We considered three possibilities for error
modes in
functional units: the output has a single bit flip; the last value computed is
returned; or a random value is returned. The former two models resulted in
significantly less quality loss than the random-value model (25\% vs.~40\%).
However, we consider the random-value model to be the most realistic, so we use it for
the results shown in Figure~\ref{enerj:fig:sensitivity}.

\subsection{Annotation Effort}
\label{enerj:effort}
Table~\ref{enerj:table:applications} lists the number of qualifiers and
endorsements used in our annotations.
Only a fraction of the types in each program must be annotated: at most 34\% of
the possible annotation sites are used.
Note that most of the applications are short programs implementing a
single algorithm (the table shows the lines of code in
each program). Our largest application, ZXing, has about 26,000 lines
of code and only 4\% of its declarations are annotated.
These rates suggest that the principal data
amenable to approximation is concentrated in a small portion of the code,
even though approximate data typically dominates the program's dynamic behavior.

Endorsements are also rare, even though our system requires one for every
approximate condition value. The outlier is ZXing, which exhibits a higher
number of endorsements due to its frequency of approximate conditions. This is
because ZXing's control flow
frequently depends on whether a particular pixel is black.

Qualitatively, we found EnerJ's annotations easy to insert. The programmer
can typically select a small set of data to approximate and then, guided by type
checking errors, ascertain associated data that must also be marked as
approximate. The requirements that conditions and array indices be precise
helped quickly distinguish data that was likely to be sensitive to error. In
some cases, such as jMonkeyEngine and Raytracer, annotation was so
straightforward that it could have been largely automated: for certain methods,
every \ilcode{float} declaration was replaced indiscriminately with an
\ilcode{@Approx float} declaration.

Classes that closely represent data are perfect candidates for
\ilcode{@Approximable} annotations. For instance, ZXing contains
\ilcode{BitArray} and \ilcode{BitMatrix} classes that are thin wrappers over
binary data. It is useful to have approximate bit matrices in some settings (e.g.,
during image processing) but precise matrices in other settings (e.g., in
checksum calculation). Similarly, the jMonkeyEngine benchmark uses a
\ilcode{Vector3f} class for much of its computation, which we marked
as approximable.
In this setting, approximate vector declarations:
%
\begin{lstlisting}
@Approx Vector3f v;
\end{lstlisting}
%
are syntactically identical to
approximate primitive-value declarations:
%
\begin{lstlisting}
@Approx int i;
\end{lstlisting}

We found that the \ilcode{@Context} annotation helped us to approach program
annotation incrementally. A commonly-used class that is a target for
approximation can be marked with \ilcode{@Context} members instead of
\ilcode{@Approx} members. This way, all the clients of the class continue to
see precise members and no additional annotation on them is immediately
necessary. The programmer can then update the clients individually to use the
approximate version of the class rather than addressing the whole program at
once.

An opportunity for algorithmic approximation also arose in ZXing. The approximable class
\ilcode{BitArray} contains a method \ilcode{isRange} that
takes two indices and determines whether all the bits between the
two indices are set. We implemented an approximate version of the method that
checks only some of the bits in the range by skipping some loop iterations.
We believe that application domain experts would use algorithmic
approximation more frequently.

In one case, we found it convenient to introduce a slight change to increase the
fault tolerance of code dealing with approximate data. ZXing has a principally
floating-point phase that performs an image perspective transform. If the
transform tried to access a coordinate outside of the image bounds,
ZXing would catch the \ilcode{ArrayIndexOutOfBoundsException} and print a
message saying that the image transform failed. We modified the algorithm to
silently return a white pixel in this case. The result was that the image
transform became more resilient to transient faults in the transformation
coordinates. We marked these coordinates as
approximate and then endorsed them at the point they are used as array
indices.
In no case, however, does an application as we annotated it do
\emph{more} computation than the pristine version.


\section{Discussion}
\label{enerj:sec:conc}

EnerJ is a language for enforcing \emph{safety} in approximate programing.
The key observation is that approximate programs tend to intermix
error-resilient and error-vulnerable work within the same program.
The former makes up the bulk of the computation and data, while the latter
provides critical structure and control.
EnerJ's brand of approximate safety protects the control components while
allowing errors in most of the program.
It borrows ideas from information-flow tracking for enforcing security to
isolate the critical data from the corrupting effects of approximation.

The next two chapters shift focus from enforcing safety
to controlling quality.
The systems described next all benefit from the separation of concerns that
EnerJ offers: they only need to analyze the approximate component of the
program.
EnerJ's focus on simpler safety properties makes
it a foundation for the more sophisticated abstractions necessary for
reasoning about quality.
